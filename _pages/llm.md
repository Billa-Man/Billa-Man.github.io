---
layout: page
title: "LLM Projects"
---

<div class="project-card">
  <div class="project-card-content">
    <h3>LLM Prompt Recovery</h3>
      <p><strong>Tech Stack:</strong> Python, Huggingface transformers, UnSloth, Azure</p>
      <p></p>
      <ul>
        <li>Developed and deployed a project aimed at reconstructing original LLM prompts used to transform specific input texts, optimizing the text generation process.</li>
        <li>Fine-tuned a LLaMA 3.2 model on an externally curated dataset created using advanced prompt engineering techniques across various open-source models. Applied preprocessing techniques and implemented LoRA (Low-Rank Adaptation) to efficiently utilize limited GPU resources.</li>
        <li>Achieved a Sharpened Cosine Similarity of <b>0.52</b>.</li>
      </ul>
      <p><a href="https://github.com/Tarun-108/HerWay">View Project</a></p>
  </div>
  <img src="/assets/projects/herway.png" alt="her-way" class="project-card-img" />
</div>


<div class="project-card">
  <div class="project-card-content">
    <h3>20 Questions</h3>
      <p><strong>Tech Stack:</strong> Python, Huggingface transformers, UnSloth, Azure</p>
      <p></p>
      <ul>
        <li>Created an agent using the LLaMA 3 8B model, fine-tuned to act as the game agent, capable of playing 20 Questions by asking strategic questions and deducing the correct answer efficiently.</li>
        <li>Implemented a binary search algorithm for the questioner, allowing the agent to efficiently narrow down possible answers by systematically eliminating options based on player responses. Combined this with reinforcement learning to enhance the model's performance over time by rewarding accurate guesses and penalizing redundant questions.</li>
      </ul>
      <p><a href="https://github.com/Tarun-108/HerWay">View Project</a></p>
  </div>
  <img src="/assets/projects/herway.png" alt="her-way" class="project-card-img" />
</div>
